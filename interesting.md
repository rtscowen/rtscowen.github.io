---
layout: page
title: Interesting & Unanswered 
permalink: /interesting/
---

# Unanswered Qs
A list of questions/things I'm curious about.

- Why do some people have more energy than others? 
    - Some people seem to be able to do many more things simultaneously without burning out
    - Some people seem to be able to enter flow states of focus really easily, other can't 
    - Can you do anything about this? Or do we just have to accept that some people are born with this ability and the rest are woefully distractible?
    - I've had some success in changing my own energy levels and focus
    - [Hunter vs farmer hypothesis](https://en.wikipedia.org/wiki/Hunter_versus_farmer_hypothesis) is a sort of directionally convincing explanation, but it's only meant to account for the ADHD population when there are significant variations in focus levels even in those without ADHD, and it doesn't explain energy levels well either
    - Saw some things about histamine in an X thread recently, bookmarking to go back to this. Reminded me of psycho-immuno-brain stuff from [When The Body Says No](https://www.amazon.co.uk/When-Body-Says-No-Hidden/dp/178504222X/ref=asc_df_178504222X?mcid=5513d45753a832d4b9461c45cf6f24c4&th=1&psc=1&tag=googshopuk-21&linkCode=df0&hvadid=697287344587&hvpos=&hvnetw=g&hvrand=5613341175471219920&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9045901&hvtargid=pla-579976941970&psc=1&gad_source=1)

- Why is denistry so imprecise compared to other parts of medicine? 
    - We can precisely distinguish exact subtypes of e.g. breast cancer, and tailor treatment accordingly. Yet the dentistry process seems very much like *vague guesture at shadow on x-ray* "you probably need a root canal, that'll be 700 pounds please, 50% success rate". What gives?

- Why is applying machine learning in production apparently so hard to get right? 
    - Lots of companies building applied ML solutions for customers seem to struggle with getting this right
    - I still do not see why this should be so difficult, on a fundamental technical level
    - I suspect a lot of this is actually a consequence of the more general ruinous trend towards extreme specialisation, software engineers being more scared of ML than they need to be, some amount of gatekeeping from people with PhDs from fancy universities 

- Common vs specific factors in psychotherapy: 
    - Stole this one from Scott Alexander to be clear, but I am still very interested
    - I have seen papers on this, and it seems basically impossible to definitively settle the matter, but does most of the effect of psychotherapy come from specific modalities (CBT/psychodynamic etc) or is most of the benefit just working with a person who is paid not to actively hate you, who wants to see you succeed etc 
    - brains as coherence orchestrating meaning machines. maybe people vary in their ability to self-referentially peek at their own meaning construction processes, or vary in how they are able to access that ability if it is somewhat latent, and this favours modality 1 vs modality 2. and the more generall able you are to do the self-referential peeking the more likely you are to be able to get something out of a wider set of modalities. Not sure, this doesn't feel particularly strong, and not my area of expertise 

- Kind internal world vs harsh internal world
    - One axis along which I divide people that I haven't seen well captured in the personality literature is kind vs harsh inner world
    - Some friends of mine (who are very outwardly friendly/agreeable), seem to almost thrive on haivng harsh internal worlds (pushing themselves to extremes, extreme perfectionism)
    - If this was captured by agreeability x neuroticism, which seem like the closest part of personality literature to this, I'd expect people like this to be outwardly disagreeable and less functional, but I know many people who aren't. 
    - I often suspect the Big Five neglects the ways in which people might have meaningful contextually dependent spikes in traits, or context specific deviations from their general scory. if the theory itself doesn't neglect this, people who use it certainly do

- Why as you move closer towards the right tail of the ability distribution are disparities between subtests on IQ tests apparently more common? 
    - I once took an IQ test, just out of curiousity. I did two tests, a verbal test and a spatial test ("performance IQ")
    - I was happy with both my scores, but I had a huge difference between my verbal score and my spatial score, with the verbal score being much higher
    - Apparently, this gets more common as you move towards the right tail (and also in people with brain lesions, that one seems a bit more obvious to explain depending on location of lesion). Why? Is this a real thing or just a quirk of the sort of people who voluntarily take IQ tests? 

# Interesting

These are areas I'm either actively working on projects in, or would be interested to in the future. If you'd like to chat or collaborate on them, reach out:

- ML/data infrastructure for doing "ML at reasonable scale" 
    - related to question above

- Psychoeducation 
    - I am a bit of a self-help junkie, and mockery aside think there are huge gains to be made from changing your mindset
    - Mindset interventions have growing literature support (I have no idea if they have/will survive the replication crisis)
    - I think in an ideal world, everyone would get to check in with a qualified psychotherapist for an MOT/tune up on how their mindset is holding them back. This isn't going to be possible. How do we scale out mindset interventions? [Example from Dr Julie Gurner](https://drgurner.substack.com/)

- Talent allocation
    - How do we allocate people better to jobs they like and will be good at? Recruiting seems extremely suboptimal at the moment
    - Talent by Tyler Cowen is a good book on assessing talent from a hiring perspective 
    - the whole process generally sucks 

- Novel and weird neural network stuff
    - I'm interested in the application of Friston's free energy principle to machine learning/neural networks: [https://jaredtumiel.github.io/blog/2020/10/14/spinning-up-in-ai.html](https://jaredtumiel.github.io/blog/2020/10/14/spinning-up-in-ai.html). I don't claim to understand free energy that well (I'm not sure anyone but Karl Friston really does), but it feels intuivitely like an area worth exploring
    - I am also interested in [brain oscillations](https://www.researchgate.net/publication/306205573_The_Human_Oscillome_and_Its_Explanatory_Potential) and whether there might be interesting parallels to exploit for inspiration in artificial learning systems. I have no real reasoned basis for wanting to do this, just seems fun